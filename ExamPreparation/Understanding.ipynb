{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the online exam, you will be provided with a google link, where you have to answer ten short questions. These will be of the type \"Define MNAR in equations.\" or \"Explain matched filtering in 2 sentences.\" \n",
    "\n",
    "You have 5 minutes to complete this part, meaning 30 seconds per question. When you submit, the timestamp of your submission is recorded. If you submit too late, you loose these points. \n",
    "\n",
    "GRADING: Each of the 10 questions gives you directly one point on a Dutch grading scale (1 to 10). Meaning if you answer all questions correctly, you would get a 10 for this part of the exam. You must answer at least 5 questions correctly to qualify for *passing the entire exam.* (You could then still fail if you show poor performance in the part \"ANALYTICS\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course timeline per week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Statistical gymnastics\n",
    "2. Basics of inference\n",
    "3. Inference in Astronomy\n",
    "4. Missing data\n",
    "5. Bayesian vs Frequentists\n",
    "6. Filtering and gravitational waves\n",
    "7. Sampling\n",
    "8. Exam preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of concepts that might be asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Missing data**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data**: No data value is stored for the variable in observation.<br>\n",
    "**MCAR**: Missing data completely at random. The probability of being missing data is the same for all cases. Implies that causes for the missing data are unrelated to the data. The difference between MAR and MCAR is that there is a variable explaining the missing data. In reality MAR and MNAR are almost never known. <br>\n",
    "**MAR**: Missing data at random. If the probability of being missing is the same only within groups defined by the observed data, then the data are missing at random. MAR is a much broader class than MCAR.<br> \n",
    "**MNAR**: Missing not completely at random. means that the probability of being missing varies for reasons that are unknown to us. <br>\n",
    "\n",
    "**Equations MCAR, MAR, MNAR**:<br>\n",
    "**MAR**: $ \\hspace{2.6mm} \\mathcal{P}(R|\\vec{\\xi},y_\\text{mis},y_\\text{obs}) = \\mathcal{P}(R|\\vec{\\xi}) $ <br>\n",
    "**MCAR**: $ \\mathcal{P}(R|\\vec{\\xi},y_\\text{mis},y_\\text{obs}) = \\mathcal{P}(R|\\vec{\\xi},y_\\text{obs}) $ <br>\n",
    "**MNAR**: $ \\mathcal{P}(R|\\vec{\\xi},y_\\text{mis},y_\\text{obs}) \\neq \\mathcal{P}(R|\\vec{\\xi},y_\\text{obs}) $ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Inference**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**: When data analysis is used to deduce properties of an underlying distribution of probability. Inference is reasoning under uncertaintiy.<br>\n",
    "**Bayesian inference**: Statistical methods for using data do update beliefs.<br>\n",
    "**Inference vs. Learning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Variables, distributions**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random variable/Stochastic variable**: A variable whose values depend on outcomes of a random phenonmenon.<br>\n",
    "**Statistical independence of two random variables**: Two random variables are independent if they convey no information about each other and, as a consequence, receiving information about one of the two does not change our assessment of the probability distribution of the other.<br>\n",
    "**Probability distribution**: Provides probabilities of occurence of difference outcomes of an experiment.<br>\n",
    "**Multivariate distribution/Joint distribution**: Generlization of a one-dimensional univariate distribution to higher dimensions.<br>\n",
    "**Conditional probability distribution**: Given two jointly distributed random variables $X$ and $Y$, the conditional probability distribution of $Y$ given $X$ is the probability distribution of $Y$ when $X$ is known to be a particular value.<br>\n",
    "**Marginal distribution**: Gives the probabilities of various values of the variables in the subset without reference to the values of the other variables. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Convariance**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance**: The expectation of the squared deviation of a random variable from its mean.<br>\n",
    "**Covariance**: A measure of the joint variability of two random variables.<br>\n",
    "**Covariance matrix**: A matrix containing all covariance values between each pair of elements of random variables.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Estimation, validation**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Likelihood function**: Measure the quality of a fitting a statistical model to a data sample.<br>\n",
    "**Maximum-likelihood estimation**: A method of estimating the parameters of a probability distribution by maximizing a likelihood function. <br>\n",
    "**Null-hypothesis**: A statement that there is not relation between two measured phenomena. <br>\n",
    "**P-values**: You can use p-values to estimate how likely something is due to noise.<br>\n",
    "**Chi-squared test**: A way to show the relationship between variables. It gives you a single number that tells you how much difference exists between two populations.<br>\n",
    "**Cross-validation**: A model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set.<br>\n",
    "**Distance measure**: A measure that quantifies the distance between two statistical objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Bayes'**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior**: The probability distribution that would express one's beliefs about an uncertain quantity before some evidence taken into acocunt.<br>\n",
    "**Posterior**: The conditional probability that is assigned after the relevant evidence is taken into account.<br>\n",
    "**Bayes' Theorem (equation)**:\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "$$ P(A|B,C) = \\frac{P(A|C)P(B|A,C)}{P(B|C)} $$\n",
    "**Bayesian Evidence**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Lesbesque**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure Theory**: Measure theory is a very abstract 'unification' of probability manipulations.<br>\n",
    "**Lebesgue-integraal**: An extension of a integral into a larger class of function, it also extends the domains on which these function can be defined.\n",
    "\n",
    "The Lebesgue integral is a modern integral definition that overcomes multiple difficulties of the older Riemann integral. It is better adapted to high-dimensional integration in complicated spaces/manifolds, and uses a measure to integrate against. The selected measure defines the meaning of the integral. The measure can e.g. assign importance or penalties to certain values of the integrand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Probability interpretations**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian vs. Frequentists**: Two different interpretations of probability theory: 'Frequentist' comes from frequency: rely on an actual or hypothetical repetition of the experiment. Bayesians interpret probability as a credibility.\n",
    "\n",
    "Terminology:\n",
    "- Bayesians: Might be true, it is false, seems convincing.\n",
    "- Frequentists: Sometimes happens, never happens, happens often.\n",
    "\n",
    "Catastrophe studies are clear Bayesians, since you repeating them isn't really preferable.\n",
    "\n",
    "Why are particle physicists typically frequentists: Because they repeat their experiments, because that is cheaper than building a new one.\n",
    "\n",
    "None of these two schools of thought is 'better' than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Filtering**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noise**: Contrary to the signal, Noise is the random irregularity within data. Data: is signal plus the noise: $x(t) = s(t) + n(t)$.<br>\n",
    "**Wavelet**: A wavelike oscillation with an amplitude that begins at $0$, increases, and then decreases back to zero. <br>\n",
    "**Wavelet decomposition**: Wavelets are filter functions which depend on both variables of a Fourier-transform pair such as f(frequency) and time (t) for gravitational waves. As gravitational waves carry information is both $t$-domain and $f$-domain, wavelets can recognize them efficiently. Detector glitches, on the other hand, are either static, or of short burst-type, and the wavelets filter these out efficiently. Thus: wavelets are used for data cleaning in GW research.<br>\n",
    "**Template bank creation**: Template bank creation is the act of storing signal shapes $\\vec{s}$ for the filter $\\vec{f}$. The templates need to be sensibly spaced in the parameters they depend on. May $\\vec{s}(p_1,p_2,p_{...})$ be the signals dependence on parameters $p_1,p_2,...$, then sensible spacing in all $p_i$ is required; otherwise waves are missed, due to bad templates.<br>\n",
    "**Filtering**: A filter is a device that removes some unwanted components or features from a signal. The goal of filtering is finding the signal in the data.<br>\n",
    "**Matched filtering**: Matched filtering is a process for detecting a known piece of signal or wavelet that is embedded in noise. A matched filter is obtained by correlating a known delayed signal, or template, with an unknown signal to detect the presence of the template in the unknown signal.\n",
    "\n",
    "The matched filter is the optimal filter to find a known signal $\\vec{s}$ in a data stream $\\vec{x} = \\vec{s} + \\vec{n}$, where $\\vec{n}$ is additive noise of covariance matrix $C$. The matched filter is then $\\vec{f} = C^{-1}\\vec{x}$, the ‘inverse varianc weighted signal’, which dominates many fields of astronomy, e.g. gravitational waveresearch, or galaxy cluster detections.\n",
    "\n",
    "Matched filtering is used to cause pipeline alerts in gravitational wave research.\n",
    "\n",
    "Occured three times in past exams.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Sampling**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling**: The selection of a subset of individuals from within a statistical populatino to estimate characteristics of the whole population. Holy grail of sampling: generate samples from a distribution such that $n(\\vec{\\theta}) \\propto P(\\vec{\\theta})$<br>\n",
    "**Rejection sampling**: Rejection sampling is a numerical technique to generate random numbers that\n",
    "follow a user-provided distribution. The idea of rejection sampling is that although we cannot easily sample from  $f(x)$, there exists another density $g(x)$, like a Normal distribution or perhaps a $t$-distribution, from which it is easy for us to sample (because there’s a built in function or someone else wrote a nice function). Then we can sample from $g(x)$ directly and then “reject” the samples in a strategic way to make the resulting “non-rejected” samples look like they came from $f(x)$. The density $g(x)$ will be referred to as the “candidate density” and $f(x)$ will be the “target density”.<br>\n",
    "**Markov property**: The conditional probability distribution of future states of the process depends only upon the present state, not on the sequence of events that preceded it. It is needed to generate Monte Carlo Markov Chains. <br>\n",
    "**Markov Chain**: A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.<br>\n",
    "**MCMC**: Markov chain Monte Carlo. A class of algorithms for sampling from a probability distribution, by constructing a Markov chain.<br>\n",
    "**Metropolis-Hastings algorithm**: A MCMC method for obtaining a sequence of random samples from a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Other**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter degeneracy**: A parameter degeneracy signifies that it is not possible to measure values of\n",
    "parameters individually. A perfect degeneracy occurs if it is fully impossible to measure them individ-\n",
    "ually, a partial degeneracy (often called ‘strong degeneracy’ in astronomy) indicates that it is difficult\n",
    "but possible under major efforts. (occured twice)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\chi^2$/degF test**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
