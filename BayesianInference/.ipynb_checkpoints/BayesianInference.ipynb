{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extragalactic radio sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a population of extragalactic radio sources: these are  complicated objects which exhibit intrinsic variations. This introduces randomness. The distribution of their flux densities is well described by a power law with slope $-\\alpha$. The likelihood to measure a radio flux $S$ is then\n",
    "\n",
    "$$ \\mathcal{P}(S|\\alpha) \\propto S^-\\alpha $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This distribution diverges at $S=0$, but telescopes can only detect a minimal limiting flux $S_0$. For $S_0 > 0$, normalize the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $\\mathcal{P}(S|\\alpha)$ describes how frequently you will find a source with flux $S$ if the Universe uses some value for $\\alpha$. Imagine now the inverse problem: You measured multiple fluxes $S$ and now want to infer $\\alpha$. Which distribution do you have to set up? Using a uniform prior and Bayes theorem, derive this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Imagine a single source has been observed, and its flux has the value $2S_0$ Which calculation do you have to carry out in order to infer the most likely value of $\\alpha$ after this single observation? Show that the m ost likely value is $\\alpha = 2.44$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the posterior of $\\alpha$. If you quoted a standard deviation for the uncertainty of $\\alpha$, which information would this omit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelling and inferring stellar properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Stefan-boltzmann law, the luminosity $L$ of a star (seen as a black body) scales with its area $A$ and temperature $T$ as\n",
    "\n",
    "$$ L = \\sigma_T A T^4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stellar temperatures result from a complicated stellar formation process and therefore vary between the stars. Assume here that the stellar temperatures are drawn from\n",
    "\n",
    "$$ T \\sim \\mathcal{G}(T_0,\\sigma) $$\n",
    "\n",
    "Derive the distribution $\\mathcal{P}(L)$ of the resulting stellar luminosities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For $T_0 = 10$, $\\sigma=1$, $A=1$, plot the distribution function of stellar luminosities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate random samples from $\\mathcal{P}(L)$, histogram them, and show that the histogram approximates $\\mathcal{P}(L)$ for sufficiently many samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Satellites: the next generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurement campaigns are frequently organized in stages. For example, an elderly satellite will be replaced by a new satellite with the same scientific task but better design. This happened e.g. when WMAP was followed up by Planck. In this context, the posterior of an old  experiment can be reinterpreted as a ‘datadriven prior’, and can then be combined with the likelihood of the new experiment, to yield the updated posterior. Here, we investigate this interplay of priors and likelihoods. Assume a data point $y$ has a Gaussian sampling distribution with mean $\\theta$ and variance $\\sigma^2$\n",
    "\n",
    "$$ y \\sim \\mathcal{G}(\\theta,\\sigma^2) $$\n",
    "\n",
    "The Gaussian is self-conjugate, i.e. a Gaussian prior times a Gaussian likelikhood will lead to a Gaussian posterior. Therefore, let us use the prior\n",
    "\n",
    "$$ \\theta \\sim \\mathcal{G}(\\mu_0,\\tau_0^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which hypter-parameters occur here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Derive the posterior $\\mathcal{P}(\\theta|y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot prior and posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For which values of the hyperparameters do you have a highly informative, or uninformative prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. If the prior describes the older experiment, what does an informative prior then express?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. If the prior does not describe any older experiment, but simply an assumed distribution which on eneeds to pick because one needs a prior after all... what does the informative prior then describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How do you have to set the hyper-parameters to reach a limit where the prior disagrees with the sampling distribution on likely values for $\\theta$? If the prior describes an older experiment, what does this disagreement then describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
